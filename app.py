import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageDraw
from deep_translator import GoogleTranslator
import easyocr
import io

st.set_page_config(page_title="Comic Translator AI")

# 注转 注 拽专 ( 拽专 专拽 驻注 转)
@st.cache_resource
def load_reader():
    return easyocr.Reader(['en'])

def process_comic(image_bytes):
    reader = load_reader()
    translator = GoogleTranslator(source='en', target='iw')
    
    # 专转 转 注
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    #  拽住 转 转
    results = reader.readtext(img)
    
    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)
    
    for (bbox, text, prob) in results:
        if prob > 0.3: #    砖 拽住
            # 拽专转 注
            (top_left, top_right, bottom_right, bottom_left) = bbox
            x, y = int(top_left[0]), int(top_left[1])
            w, h = int(bottom_right[0] - x), int(bottom_right[1] - y)
            
            # 1. 拽转 拽住 拽专 (爪注 )
            draw.rectangle([x-2, y-2, x+w+2, y+h+2], fill="white")
            
            # 2. 转专 拽住 砖爪
            try:
                translated = translator.translate(text)
                # 转转 转专 (爪专 驻砖 转)
                draw.text((x, y), translated, fill="black")
            except:
                pass

    return pil_img

st.title(" 转专 拽拽住 ")

file = st.file_uploader("注 转", type=["jpg", "png", "jpeg"])

if file:
    img_data = file.read()
    st.image(img_data, caption="拽专", use_container_width=True)
    
    if st.button("转专 注砖"):
        with st.spinner(" 转转 拽专转 转 拽拽住...  拽 拽..."):
            result = process_comic(img_data)
            st.image(result, caption="转爪 转专转", use_container_width=True)
